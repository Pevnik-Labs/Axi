\documentclass{beamer}
\usepackage[utf8]{inputenc}
\usepackage{babel}
\usepackage{xcolor}
\usepackage{AxiCommands}

\usetheme{Darmstadt}

\title{Axi Design Musings}
\author{Wojciech Ko≈Çowski}
\date{17 December 2024}

\begin{document}

\frame{\titlepage}

\section{Intro}

\begin{frame}{Intro}

The purpose of this presentation is to discuss Axi design in an informal setting. I want to bring some important considerations to the participants' collective consciousness and ponder them loosely, without getting into much technical detail.

\end{frame}

\begin{frame}{Table of contents}

\tableofcontents

\end{frame}

\begin{frame}{Plan of the presentation}

\begin{itemize}
  \item Why languages have layers.
  \item Do we need Axi?
  \item The programming layer.
  \item The logical layer.
  \item The tactic layer.
  \item The module layer.
  \item Language features.
\end{itemize}

\end{frame}

\section{Layers}

\begin{frame}{Why English is a bad logical system}

\begin{center}
  This sentence is false.
\end{center}

\vspace{2em}

Is the above sentence true or false? If we assume it is false, then apparently it tells the truth about itself, so it is true... but if we assume it is true, then it lies about itself, so it is false.

\vspace{2em}

This situation is deeply problematic -- it demonstrates that the English language doesn't fit into the confines of classical logic. We could try to analyze it as fitting some other kind of logical system, but alas, that would also fail -- G\"odel's incompleteness theorem

put on our philosopher hats and try to escape the problem by 

\end{frame}

\section{Do we need Axi?}

\begin{frame}{No}

Just kidding :)

\end{frame}

\begin{frame}{Code on-chain or off-chain?}

\end{frame}

\begin{frame}{? Source code on chain or compiled code on chain? }

\end{frame}

\section{GAS BILLS}

\begin{frame}{Some jargon}

``Semantics'' or ``dynamic semantics'' refers to the meaning and behaviour of programs at run-time.

\vspace{2em}

``Type system'' or ``static semantics'' refers to the constraints that are automatically checked before running programs.

\vspace{2em}

``Logic'' or ``proving'' refers to the correctness guarantees of programs that need to be proved manually. They are also pre-runtime.

\end{frame}

\begin{frame}{What does a programming language consist of?}

\begin{itemize}
  \item Concrete syntax (what the programmer writes).
  \item Abstract syntax (the internal representation of what the programmer wrote).
  \item Operational semantics (how programs are executed).
  \item Type system (which programs are ok).
\end{itemize}

\end{frame}

\section{Execution}

\begin{frame}{Paying for on-chain execution}

Execution of programs on-chain needs to be paid for. If it weren't, a malicious user could ask the blockchain to execute some really long-running program, or even worse, a non-terminating program, stalling the chain for long or forever. To prevent this, we require users to pay gas for executing their programs.

\end{frame}

\begin{frame}{Cost semantics}

The language's operational semantics tell us how how computation proceeds. We can extend it with \textbf{cost semantics} which will also tell us how much that computation costs in terms of some resources, like time, memory or \textbf{gas}.

\vspace{2em}

Since computation on-chain costs gas, Axi will need a cost semantics. 

\end{frame}

\begin{frame}{Cost semantics -- a research opportunity}

There's also a research opportunity. Since Axi will have a formal specification and powerful logic built-in, a question arises: can we do anything cool with the cost semantics, like proving upper bounds on gas costs?

\vspace{2em}

Note that the naive approach to this topic doesn't work, because programs that do the same thing (and thus are considered equal by the logic) may nevertheless use different amounts of resources. For example, programs which implement quick sort and selection sort are equal because for all inputs they return the same outputs (there's only one way of correctly sorting a list), but their time complexities are different (and so would be their ``gas complexities'').

\end{frame}

\begin{frame}{Out-of-gas exception in the operational semantics?}

A question arises: do we need to model out-of-gas situations in the language semantics?

\begin{itemize}
  \item On the one hand, programs written in proof assistants (Coq, Lean, Agda) can encounter plenty of run-time problems, like stack overflows, but usually the operational semantics isn't concerned with them because it represents execution on an idealized computer.
  \item On the other hand, it would make the semantics more realistic and more in line with the actual implementation of the VM (there are techniques to automatically turn a language semantics into a corresponding abstract machine).
  
\end{itemize}

\vspace{2em}

I think it would be preferable to not have to deal with out-of-gas situations in the operational semantics...

\end{frame}

\begin{frame}{No out-of-gas exception in the type system}

If we have the out-of-gas exception in the semantics, further questions arise -- should we track it at the type system level?

\vspace{2em}

It seems that the out-of-gas exception:
\begin{itemize}
  \item Cannot be thrown by the programmer, as gas depends on VM internals.
  \item Cannot be caught by the programmer, as the program can't proceed anyway, because it ran out of gas.
\end{itemize}

\vspace{2em}

So it seems having the out-of-gas exception at the type system level is pointless, but I might be wrong.

\end{frame}

\section{Type checking}

\begin{frame}{Type checking -- on-chain, not off-chain}

Before running a program we need to type check it to make sure it doesn't contain obvious errors. A question arises: is the type-checking performed off-chain or on-chain?

\vspace{2em}

Type checking off-chain might seem preferable, because we don't need to pay for it (or rather, it's just much cheaper). However, what guarantees would we have that programs on-chain are well-typed? If type checking happened off-chain, an attacker could execute an ill-typed program on-chain, causing a crash. The only ways to avoid this is either performing type checking during run-time, which means the language effectively becomes dynamically typed, or performing type checking on-chain before execution.

\end{frame}

\begin{frame}{Type checking on-chain -- questions}

With type checking happening on-chain, even more questions arise.

\begin{itemize}
  \item Does the user need to pay gas for type checking?
  \item What's the time complexity of the type checker?
  \item Does the type checker need its own cost semantics?
\end{itemize}

\end{frame}

\begin{frame}{Paying for type checking}

Since type checking happens on-chain and requires computational resources (mostly time), having to pay for it seems like a very reasonable default.

\vspace{2em}

However, I have a really bad feeling about this. It's hard to even imagine what kind of demon it would summon, especially when faced by non FP-savvy programmers.

\end{frame}

\begin{frame}{Arguments against paid type checking}

\begin{itemize}
  \item Possible perverse incentives to the programmer. It could be that weaker and less informative types are cheaper to type check, which would result in less incentives to follow best practices, which leads to weaker correctness guarantees, and that runs directly counter to the entire point of having formal proofs.
  \item Possible perverse incentives to us! We have less incentives to find smart solutions, since money can solve all the problems.
  \item It makes the cost semantics of the language much less useful, becuase execution ceases to be the only cost. It also completely obliterates the research opportunities with respect to the cost semantics, because proving stuff about the cost of the type checking is a completely different kettle of fish from proving stuff about the cost of the program.
\end{itemize}

\end{frame}

\begin{frame}{Free typing for the masses}

I believe that typing must be free or else we are facing a scary and unknown territory full of bad things...

\vspace{2em}

Let's to find out what the complexity of typing is and try to come up with some kind of a solution to this dire problem.

\end{frame}

\begin{frame}{Type inference and type checking}

Typing might be split into two related problems, type checking and type inference:

\begin{itemize}
  \item In type checking, you get the term and its type as input and you need to check whether this term has this type.
  \item In type inference, you get the term as input and you need to find its type (preferably the best possible type -- the \textit{principal type} -- if it exists).
\end{itemize}

\vspace{2em}

It's easy to see that type checking can be reduced to type inference: just infer the type and compare it with the input type.

\vspace{2em}

Also note that often, ``type checking'' is used as a synonym to ``typing''.

\end{frame}

\begin{frame}{Complexity of typing -- intro}

The problems of type checking and type inference are somewhat fragile to talk about, because even for a particular kind of language (we will consider STLC, System F and CoC), a lot depends on the concrete variant of the language in consideration. Also, nobody talks about it, because usually it doesn't matter.

\vspace{2em}

We will discuss two simple cases: no annotations at all, and ``enough'' or ``all'' annotations that we could wish for.

\end{frame}

\begin{frame}{Complexity of typing -- no annotations}

\begin{table}
  \centering
  \begin{tabular}{|c|c|c|}
    \hline
                   & Checking    & Inference   \\ \hline
    STLC           & P-complete  & P-complete  \\ \hline
    System F       & undecidable & undecidable \\ \hline
    CoC            & undecidable & undecidable \\ \hline
  \end{tabular}
\end{table}

In case there are no annotations whatsoever, the matter is rather simple. A quick search reveals that typing for STLC is P-complete, i.e. can be done in polynomial time, but is as hard as the hardest problems in P. GPT tells me that the actual complexity is $O(n^2)$ and the typical case takes linear time.

\vspace{2em}

However, as soon as we wander into polymorphism (System F), inference becomes undecidable (and so does checking, which is equivalent to it). CoC is even more powerful, so also undecidable.

\end{frame}

\begin{frame}{Complexity of typing -- enough annotations}

\vspace{1em}

\begin{table}
  \centering
  \begin{tabular}{|c|c|c|}
    \hline
             & Checking  & Inference \\ \hline
    STLC     & Linear    & Linear    \\ \hline
    System F & Linear    & Linear    \\ \hline
    CoC      & decidable & decidable \\ \hline
  \end{tabular}
\end{table}

\vspace{2em}

With enough annotations, the situation changes drastically -- checking and inference for both STLC and System F now take linear time (but note that annotations that guarantee fast checking don't necessarily guarantee fast inference).

\vspace{2em}

The situation for CoC also changes, although with enough annotations both problems become merely decidable -- the source of complexity is different than in System F, as we will soon see.

\end{frame}

\begin{frame}{Hindley-Milner}

So far we've been talking about problems and giving answers in terms of complexity classes or decidability. Let's see how things look for something more down to earth, like the Hindley-Milner (HM) type inference.

\vspace{1em}

HM is a type system with polymorphism, but weaker than System F. HM polymorphism is prenex and rank-1, i.e. quantifiers are allowed only at the top-level and they cannot be nested. The HM type system is so simple that it admits a complete type inference algorithm that can always find a principal (i.e. best, most general) type. Type checking is performed by comparing the inferred type with the input type.

\vspace{1em}

HM lays at the foundation of languages like Haskell or OCaml. It is old and venerable, but rather outdated.

\end{frame}

\begin{frame}{Complexity of HM type inference}

HM type inference  in the worst case takes time doubly exponential in the size of the program. For example:

\begin{itemize}
  \item $f_0(x) = (x, x)$
  \item $f_{n + 1} = f_n \circ f_n$
\end{itemize}

\vspace{2em}

If I'm not mistaken, there should be $2^{2^n}$ type variables in the type of $f_n$. Note that the indexing over $n$ happens at the meta-level, ie. we can't define $f$ in HM, but we can manually define $f_n$ for any $n$.

\vspace{2em}

So in theory, HM is really bad. But in practice, it works well and fast. What gives?

\end{frame}

\begin{frame}{A possible solution (MP)}

\begin{itemize}
  \item Typing is split into two phases: off-chain and on-chain.
  \item The off-chain phase can have comfortable type inference, possibly with bad complexity, and other goodies.
  \item In addition to typing a term $t$, the off-chain phase also synthesises a new term $t'$, which has the same computational behaviour, but more type annotations.
  \item The on-chain phase type checks the term $t'$ in linear time.
  \item Since the on-chain phase takes linear time, we don't charge gas for it, but instead amortize the cost over the execution cost (or maybe not, maybe we can just make it free).
\end{itemize}

\end{frame}

\begin{frame}{Downsides of the possible solution}

\begin{itemize}
  \item The new term $t'$ can possibly be (doubly) exponentially bigger than the term $t$ (see the Hindley-Milner example).
  \item Since $t'$ can be exponentially bigger, the on-chain phase can still be exponentially expensive! That makes amortization over the execution cost pointless.
  \item Even if the size of $t'$ is not a problem, it still looks different from $t$, which is a bit unsettling -- after all, off-chain we wrote $t$ (and proved theorems about $t$), but on-chain we see $t'$.
\end{itemize}

\end{frame}

\begin{frame}{But it can work}

\begin{itemize}
  \item Synthesis must produce a term from which the original term can be easily reconstructed. This probably means that there will need to be two kinds of type annotations, programmer's annotations and autogenerated annotations.
  \item When deploying code, we show the user the synthesized term, and he must accept.
  \item Type checking is free and not amortized over execution, but the user pays for storage on-chain. It could mean there are different rates for data and code, since code must be type checked, but data does not.
\end{itemize}

\end{frame}

\begin{frame}{Paying for on-chain storage -- another demon}

Just as I had a bad feeling about paying for the type checking, I have a bad feeling about paying for storage of code.

\vspace{2em}

There are more perverse incentives lurking around the corner. For example, minified code takes less space than pristine code, so it is cheaper. Websites often minify their JS code for this reason.

\vspace{2em}

We would probably need some more precautions here, like computing the gas cost of storage based on the abstract syntax of the code instead of the concrete syntax. This still has some perverse incentives, as there are equivalent programs with different ASTs, and the cheaper one doesn't need to be the most clear one, but they are far smaller.

\end{frame}

\section{Proof checking}

\begin{frame}{Paying for proof checking}

The start point for proof checking is the same as for type checking: it takes time, so it makes sense to charge gas for it.
 
\vspace{2em}

I argued that paying for type checking is bad, so what about proof checking? This time, I'm actually not sure.

\vspace{2em}

Let's start by establishing a basic fact: given enough annotations, proof checking is decidable (of course it is, otherwise all these proof assistants wouldn't exist in the first place).

\end{frame}

\begin{frame}{Hello, Ackermann}

Consider the following function, called the Ackermann function:

\begin{itemize}
  \item $f(0, n) = n + 1$
  \item $f(m + 1, 0) = f(m, 1)$
  \item $f(m + 1, n + 1) = f(n, f(m + 1, n))$
\end{itemize}

\vspace{2em}

This function, even though it might not look like it, grows really fast, and this fact can be used to prove that it is not primitive recursive, which in turn means it takes a really long time to compute it.

\end{frame}

\begin{frame}{Complexity of proof checking}

If our programming language has function types and recursion over the naturals, we can define the Ackermann function.

\vspace{2em}

If our logic has the conversion rule, we can prove that the Ackermann function, for some big input, returns an even bigger output, but that requires actually performing the computation, which takes long.

\vspace{2em}

Therefore, proof checking is decidable (given enough annotations), but not primitive recursive. This means that checking a proof can take a more or less arbitrarily long, but finite time, i.e. it is guaranteed to terminate.

\end{frame}

\end{document}