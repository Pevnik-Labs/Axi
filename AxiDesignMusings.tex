\documentclass{beamer}
\usepackage[utf8]{inputenc}
\usepackage{babel}
\usepackage{xcolor}
\usepackage{AxiCommands}

\usetheme{Darmstadt}

\title{Axi Design Musings}
\author{Wojciech Ko≈Çowski}
\date{17 December 2024}

\begin{document}

\frame{\titlepage}

\section{Intro}

\begin{frame}{Intro}

The purpose of this presentation is to discuss Axi design in an informal setting. I want to bring some important considerations to the participants' collective consciousness and ponder them loosely, without getting into much technical detail.

\end{frame}

\begin{frame}{Table of contents}

\tableofcontents

\end{frame}

\begin{frame}{Plan of the presentation}

\begin{itemize}
  \item Why languages have layers.
  \item Do we need Axi?
  \item The programming layer.
  \item The logical layer.
  \item The tactic layer.
  \item The module layer.
  \item Language features.
\end{itemize}

\end{frame}

\section{Layers}

\begin{frame}{Why English is a bad logical system}

\begin{center}
  This sentence is false.
\end{center}

\vspace{2em}

Is the above sentence true or false? If we assume it is false, then apparently it tells the truth about itself, so it is true... but if we assume it is true, then it lies about itself, so it is false.

\vspace{2em}

This situation is deeply problematic -- it demonstrates that the English language doesn't fit into the confines of classical logic. We could try to analyze it as fitting some other kind of logical system, but alas, that would also fail -- G\"odel's incompleteness theorem

put on our philosopher hats and try to escape the problem by 

\end{frame}

\section{Do we need Axi?}

\begin{frame}{No}

Just kidding :)

\end{frame}

\begin{frame}{Code on-chain or off-chain?}

\end{frame}

\begin{frame}{? Source code on chain or compiled code on chain? }

\end{frame}

\section{GAS BILLS}

\begin{frame}{Some jargon}

``Semantics'' or ``dynamic semantics'' refers to the meaning and behaviour of programs at run-time.

\vspace{2em}

``Type system'' or ``static semantics'' refers to the constraints that are automatically checked before running programs.

\vspace{2em}

``Logic'' or ``proving'' refers to the correctness guarantees of programs that need to be proved manually. They are also pre-runtime.

\end{frame}

\begin{frame}{What does a programming language consist of?}

\begin{itemize}
  \item Concrete syntax (what the programmer writes).
  \item Abstract syntax (the internal representation of what the programmer wrote).
  \item Operational semantics (how programs are executed).
  \item Type system (which programs are ok).
\end{itemize}

\end{frame}

\section{Execution}

\begin{frame}{Paying for on-chain execution}

Execution of programs on-chain needs to be paid for. If it weren't, a malicious user could ask the blockchain to execute some really long-running program, or even worse, a non-terminating program, stalling the chain for long or forever. To prevent this, we require users to pay gas for executing their programs.

\end{frame}

\begin{frame}{Cost semantics}

The language's operational semantics tell us how how computation proceeds. We can extend it with \textbf{cost semantics} which will also tell us how much that computation costs in terms of some resources, like time, memory or \textbf{gas}.

\vspace{2em}

Since computation on-chain costs gas, Axi will need a cost semantics. 

\end{frame}

\begin{frame}{Cost semantics -- a research opportunity}

There's also a research opportunity. Since Axi will have a formal specification and powerful logic built-in, a question arises: can we do anything cool with the cost semantics, like proving upper bounds on gas costs?

\vspace{2em}

Note that the naive approach to this topic doesn't work, because programs that do the same thing (and thus are considered equal by the logic) may nevertheless use different amounts of resources. For example, programs which implement quick sort and selection sort are equal because for all inputs they return the same outputs (there's only one way of correctly sorting a list), but their time complexities are different (and so would be their ``gas complexities'').

\end{frame}

\begin{frame}{Out-of-gas exception in the operational semantics?}

A question arises: do we need to model out-of-gas situations in the language semantics?

\begin{itemize}
  \item On the one hand, programs written in proof assistants (Coq, Lean, Agda) can encounter plenty of run-time problems, like stack overflows, but usually the operational semantics isn't concerned with them because it represents execution on an idealized computer.
  \item On the other hand, it would make the semantics more realistic and more in line with the actual implementation of the VM (there are techniques to automatically turn a language semantics into a corresponding abstract machine).
  
\end{itemize}

\vspace{2em}

I think it would be preferable to not have to deal with out-of-gas situations in the operational semantics...

\end{frame}

\begin{frame}{No out-of-gas exception in the type system}

If we have the out-of-gas exception in the semantics, further questions arise -- should we track it at the type system level?

\vspace{2em}

It seems that the out-of-gas exception:
\begin{itemize}
  \item Cannot be thrown by the programmer, as gas depends on VM internals.
  \item Cannot be caught by the programmer, as the program can't proceed anyway, because it ran out of gas.
\end{itemize}

\vspace{2em}

So it seems having the out-of-gas exception at the type system level is pointless, but I might be wrong.

\end{frame}

\section{Type checking}

\begin{frame}{Type checking -- on-chain, not off-chain}

Before running a program we need to type check it to make sure it doesn't contain obvious errors. A question arises: is the type-checking performed off-chain or on-chain?

\vspace{2em}

Type checking off-chain might seem preferable, because we don't need to pay for it (or rather, it's just much cheaper). However, what guarantees would we have that programs on-chain are well-typed? If type checking happened off-chain, an attacker could execute an ill-typed program on-chain, causing a crash. The only ways to avoid this is either performing type checking during run-time, which means the language effectively becomes dynamically typed, or performing type checking on-chain before execution.

\end{frame}

\begin{frame}{Type checking on-chain -- questions}

With type checking happening on-chain, even more questions arise.

\begin{itemize}
  \item What's the time complexity of the type checker?
  \item Does the user need to pay gas for type checking?
  \item Does the type checker need its own cost semantics?
\end{itemize}

\end{frame}

\begin{frame}{Complexity of (Hindley-Milner) type inference}

Hindley-Milner type inference (the foundation for languages like Haskell or OCaml) in the worst case takes time doubly exponential in the size of the program (example: $f_0(x) = (x, x); f_{n + 1} = f_n \circ f_n$; if I'm not mistaken, there should be $2^{2^n}$ type variables in the type of $f_n$).

\vspace{2em}

So in theory, Hindley-Milner is really bad. But in practice, it works well and fast. What gives?

\end{frame}

\begin{frame}{Type inference vs type checking}

Wait a sec, so far I've been mostly talking about type checking, but Hindley-Milner is type inference, not type checking. In case you're missing the difference:

\begin{itemize}
  \item In type inference, you get the term as input and you need to output its type
  \item In type checking, you get the term and its type as input and you need to check whether they are a good match.
\end{itemize}

\vspace{2em}

It's easy to see that type checking can be reduced to type inference: just infer the type and compare it with the input type.

\vspace{2em}

\end{frame}

\begin{frame}{Complexity of type checking and type inference}

\vspace{1em}

\begin{table}
  \centering
  \begin{tabular}{|c|c|c|}
    \hline
                   & Checking       & Inference          \\ \hline
    STLC           & PTIME-complete & PTIME-complete     \\ \hline
    Hindley-Milner &                & doubly exponential \\ \hline
    System F       & undecidable    & undecidable        \\ \hline
    CoC            & undecidable    & undecidable        \\ \hline
  \end{tabular}
  \caption{No annotations}
\end{table}

\begin{table}
  \centering
  \begin{tabular}{|c|c|c|}
    \hline
             & Checking  & Inference \\ \hline
    STLC     & Linear    & Linear    \\ \hline
    System F & Linear    & Linear    \\ \hline
    CoC      & decidable & decidable \\ \hline
  \end{tabular}
  \caption{All/enough annotations}
\end{table}

\end{frame}

\begin{frame}{Paying for type checking}

Since type checking happens on-chain and requires computational resources (mostly time), having to pay for it seems like a very reasonable default.

\vspace{2em}

However, I have a really bad feeling about this. It's hard to even imagine what kind of perverse incentives it would give to the programmer, especially one that is not FP-savvy. It could be that these incentives run counter to good practices, like when weaker or less informative types are cheaper to type check than stronger and more informative ones. This would result in weaker correctness guaranties, which is pretty incompatible with the entire formal logic thing.

\end{frame}

\begin{frame}{Arguments against paid type checking}

\begin{itemize}
  \item Possible perverse incentives to the programmer, as mentioned above.
  \item Possible perverse incentives to us! We have less incentives to find smart solutions, since money can solve all the problems.
  \item It makes the cost semantics of the language much less useful, becuase execution ceases to be the only cost.
  \item It completely obliterates the research opportunities with respect to the cost semantics, because proving stuff about the cost of the type checking is a completely different kettle of fish from proving stuff about the cost of the program.
  \item 
\end{itemize}

\end{frame}

\begin{frame}{A possible solution (MP)}

\begin{itemize}
  \item Typing is split into two phases: off-chain and on-chain.
  \item The off-chain phase can have comfortable type inference, possibly with bad complexity, and other goodies.
  \item In addition to typing a term $t$, the off-chain phase also synthesises a new term $t'$, which has the same computational behaviour, but more type annotations.
  \item The on-chain phase type checks the term $t'$ in linear time.
  \item Since the on-chain phase takes linear time, we don't charge gas for it, but instead amortize the cost over the execution cost (or maybe not, maybe we can just make it free).
\end{itemize}

\end{frame}

\begin{frame}{Downsides of the possible solution}

\begin{itemize}
  \item The new term $t'$ can possibly be (doubly) exponentially bigger than the term $t$ (see the Hindley-Milner example).
  \item Since $t'$ can be exponentially bigger, the on-chain phase can still be exponentially expensive! That makes amortization over the execution cost pointless.
  \item Even if the size of $t'$ is not a problem, it still looks different from $t$, which is a bit unsettling -- after all, off-chain we wrote $t$ (and proved theorems about $t$), but on-chain we see $t'$.
\end{itemize}

\end{frame}

\begin{frame}{But it can work}

\begin{itemize}
  \item Synthesis must produce a term from which the original term can be easily reconstructed. This probably means that there will need to be two kinds of type annotations, programmer's annotations and autogenerated annotations.
  \item When deploying code, we show the user the synthesized term, and he must accept.
  \item Type checking is free and not amortized over execution, but the user pays for storage on-chain.
\end{itemize}

\end{frame}

\section{Proof checking}

\begin{frame}{Paying for proof checking}

\end{frame}

\end{document}